{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "style transfer只是将全图的纹理信息整合到了content img上，但是画画时，在每一种风格下，不同的物体有不同边缘画法，会拉出不一样的线条长度，这些才是关键的画师技巧，简单的将一张图片上的纹理强行烙印在另一张图片上并不是创作。比如style图中房子物体的画法，其纹理将被直接复制在content img上，即使content img上对应部分并不是一个房子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(download_link, file_name, expected_bytes):\n",
    "    #下载VGG-19预训练模型\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"VGG-19 pre-trained model is ready\")\n",
    "        return\n",
    "    print(\"Downloading the VGG pre-trained model.This might take a while ...\")\n",
    "    file_name , _ = urllib.request.urlretrieve(download_link, file_name)\n",
    "    file_stat = os.stat(file_name)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print(\"Successfully downloaded VGG-19 pre-trained model\", file_name)\n",
    "    else:\n",
    "        raise Exception(\"File\" + file_name + \" might be corrupted. You should try downloading it with a browser.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resized_image(img_path, width, height, save = True):\n",
    "    image = Image.open(img_path)\n",
    "    image = ImageOps.fit(image,(width, height), Image.ANTIALIAS)\n",
    "    if save:\n",
    "        image_dirs = img_path.split('/')\n",
    "        image_dirs[-1] = 'resized ' + image_dirs[-1]\n",
    "        out_path = '/'.join(image_dirs)\n",
    "        if not os.path.exists(out_path):\n",
    "            image.save(out_path)\n",
    "    image = np.asarray(image,np.float32)\n",
    "    return np.expand_dims(image, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, width, height, noise_ratio=0.6):\n",
    "    noise_image = np.random.uniform(-20,20,(1,height,width,3)).astype(np.float32)\n",
    "    return noise_image * noise_ratio + content_image*(1 - noise_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(path, image):\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mkdir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_vgg_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat'\n",
    "VGG_FILENAME = 'imagenet-vgg-verydeep-19.mat'\n",
    "EXPECTED_BYTES = 534904783"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self.vgg_layers[0][layer_idx]的结构\n",
    "conv->e.g: layers{1,1}:{name,type,weights,size,pad,stride,precious,dilate,opts}\n",
    "relu->e.g: layers{1,2}:{name,type,leak,weights,precious}\n",
    "pool->e.g: layers{1,5}:{name,type,method,pool,stride,pad,weights,precious,opts}\n",
    "layers{1,1}:[[{A1,A2,A3,A4,A5,A6,A7,A8,A9}]]其中A3=[[{A3_1,A3_2}]]对应w,b\n",
    "所以[0][0][2][0][0]对应W,[0][0][2][0][1]对应b\n",
    "\n",
    "[[(array(['conv1_1'], dtype='<U7'), array(['conv'], dtype='<U4'), array([[array([[[[ 0.39416704, -0.08419707, -0.03631314, ..., -0.10720515,\n",
    "           -0.03804016,  0.04690642],\n",
    "         [ 0.46418372,  0.03355668,  0.10245045, ..., -0.06945956,\n",
    "          -0.04020201,  0.04048637],\n",
    "         [ 0.34119523,  0.09563112,  0.0177449 , ..., -0.11436455,\n",
    "          -0.05099866, -0.00299793]],\n",
    "\n",
    "        [[ 0.37740308, -0.07876257, -0.04775979, ..., -0.11827433,\n",
    "          -0.19008617, -0.01889699],\n",
    "         [ 0.41810837,  0.05260524,  0.09755926, ..., -0.09385028,\n",
    "          -0.20492788, -0.0573062 ],\n",
    "         [ 0.33999205,  0.13363543,  0.02129423, ..., -0.13025227,\n",
    "          -0.16508926, -0.06969624]],\n",
    "\n",
    "        [[-0.04594866, -0.11583115, -0.14462094, ..., -0.12290562,\n",
    "          -0.35782176, -0.27979308],\n",
    "         [-0.04806903, -0.00658076, -0.02234544, ..., -0.0878844 ,\n",
    "          -0.3915486 , -0.34632796],\n",
    "         [-0.04484424,  0.06471398, -0.07631404, ..., -0.12629718,\n",
    "          -0.29905206, -0.2825364 ]]],\n",
    "\n",
    "\n",
    "       [[[ 0.2671299 , -0.07969447,  0.05988706, ..., -0.09225675,\n",
    "           0.31764674,  0.42209673],\n",
    "         [ 0.30511212,  0.05677647,  0.21688674, ..., -0.06828708,\n",
    "           0.3440761 ,  0.44033417],\n",
    "         [ 0.23215917,  0.133657  ,  0.12134422, ..., -0.1063385 ,\n",
    "           0.28406844,  0.3594997 ]],\n",
    "\n",
    "        [[ 0.09986369, -0.06240906,  0.07442063, ..., -0.02214639,\n",
    "           0.25912452,  0.423499  ],\n",
    "         [ 0.10385381,  0.08851637,  0.2392226 , ..., -0.01210995,\n",
    "           0.27064082,  0.40848857],\n",
    "         [ 0.08978214,  0.18505956,  0.15264879, ..., -0.04266965,\n",
    "           0.25779948,  0.35873157]],\n",
    "\n",
    "        [[-0.34100872, -0.13399366, -0.11510294, ..., -0.11911335,\n",
    "          -0.23109646, -0.19202407],\n",
    "         [-0.37314063, -0.00698938,  0.02153259, ..., -0.09827439,\n",
    "          -0.2535741 , -0.25541356],\n",
    "         [-0.30331427,  0.08002605, -0.03926321, ..., -0.12958746,\n",
    "          -0.19778992, -0.21510386]]],\n",
    "\n",
    "\n",
    "       [[[-0.07573577, -0.07806503, -0.03540679, ..., -0.1208065 ,\n",
    "           0.20088433,  0.09790061],\n",
    "         [-0.07646758,  0.03879711,  0.09974211, ..., -0.08732687,\n",
    "           0.2247974 ,  0.10158388],\n",
    "         [-0.07260918,  0.10084777,  0.01313597, ..., -0.12594968,\n",
    "           0.1464741 ,  0.05009392]],\n",
    "\n",
    "        [[-0.2803425 , -0.07094654, -0.0387974 , ..., -0.08843154,\n",
    "           0.18996507,  0.07766484],\n",
    "         [-0.3107071 ,  0.06031388,  0.10412455, ..., -0.06832542,\n",
    "           0.20279962,  0.05222717],\n",
    "         [-0.246675  ,  0.1414054 ,  0.02605635, ..., -0.10128672,\n",
    "           0.16340195,  0.02832468]],\n",
    "\n",
    "        [[-0.41602272, -0.11491341, -0.14672887, ..., -0.13079506,\n",
    "          -0.1379628 , -0.2658845 ],\n",
    "         [-0.46453714, -0.00576723, -0.02660675, ..., -0.10017379,\n",
    "          -0.15603794, -0.32566148],\n",
    "         [-0.33683276,  0.06601517, -0.08144748, ..., -0.13460518,\n",
    "          -0.1342358 , -0.27096185]]]], dtype=float32),\n",
    "        array([[ 0.7301776 ],\n",
    "       [ 0.06493629],\n",
    "       [ 0.03428847],\n",
    "       [ 0.8260386 ],\n",
    "       [ 0.2578029 ],\n",
    "       [ 0.54867655],\n",
    "       [-0.01243854],\n",
    "       [ 0.34789944],\n",
    "       [ 0.5510871 ],\n",
    "       [ 0.06297145],\n",
    "       [ 0.6069906 ],\n",
    "       [ 0.26703122],\n",
    "       [ 0.649414  ],\n",
    "       [ 0.17073655],\n",
    "       [ 0.4772309 ],\n",
    "       [ 0.38250586],\n",
    "       [ 0.46373144],\n",
    "       [ 0.21496128],\n",
    "       [ 0.46911287],\n",
    "       [ 0.23825859],\n",
    "       [ 0.4751922 ],\n",
    "       [ 0.70606434],\n",
    "       [ 0.27007523],\n",
    "       [ 0.6855273 ],\n",
    "       [ 0.03216552],\n",
    "       [ 0.6025288 ],\n",
    "       [ 0.3503486 ],\n",
    "       [ 0.446798  ],\n",
    "       [ 0.7732652 ],\n",
    "       [ 0.58191687],\n",
    "       [ 0.39083108],\n",
    "       [ 1.7519354 ],\n",
    "       [ 0.66117406],\n",
    "       [ 0.30213955],\n",
    "       [ 0.53059655],\n",
    "       [ 0.6773747 ],\n",
    "       [ 0.33273223],\n",
    "       [ 0.49127793],\n",
    "       [ 0.26548928],\n",
    "       [ 0.18805602],\n",
    "       [ 0.07412001],\n",
    "       [ 1.1081088 ],\n",
    "       [ 0.28224325],\n",
    "       [ 0.86755145],\n",
    "       [ 0.19422948],\n",
    "       [ 0.810332  ],\n",
    "       [ 0.36062282],\n",
    "       [ 0.5072004 ],\n",
    "       [ 0.42472315],\n",
    "       [ 0.49632648],\n",
    "       [ 0.15117475],\n",
    "       [ 0.79454446],\n",
    "       [ 0.33494323],\n",
    "       [ 0.47283995],\n",
    "       [ 0.41552398],\n",
    "       [ 0.08496041],\n",
    "       [ 0.37947032],\n",
    "       [ 0.6006739 ],\n",
    "       [ 0.47174454],\n",
    "       [ 0.8130921 ],\n",
    "       [ 0.45521152],\n",
    "       [ 1.0892007 ],\n",
    "       [ 0.47757268],\n",
    "       [ 0.4072122 ]], dtype=float32)]], dtype=object), array([[ 3,  3,  3, 64]], dtype=uint8), array([[1, 1, 1, 1]], dtype=uint8), array([[1, 1]], dtype=uint8), array([[0]], dtype=uint8), array([[1]], dtype=uint8), array([], shape=(0, 0), dtype=object))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(object):\n",
    "    def __init__(self, input_img):\n",
    "        download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n",
    "        #将layers标记转为dict\n",
    "        self.vgg_layers = scipy.io.loadmat(VGG_FILENAME)['layers']\n",
    "        #要被计算的图片\n",
    "        self.input_img = input_img\n",
    "        #对三个维度做平均中心化使用的参数\n",
    "        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "        \n",
    "    def _weights(self,layer_idx, expected_layer_name):\n",
    "        #获取训练好的VGG网络的layer_idx层的权值和偏置\n",
    "        #每层按 卷积 relu 卷积 relu maxpooling\n",
    "        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n",
    "        #print(self.vgg_layers[0][layer_idx])\n",
    "        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n",
    "        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b.reshape(b.size)\n",
    "    \n",
    "    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n",
    "        \"\"\"返回应用了vgg每层W,b的计算结果，并添加relu计算\"\"\"\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            W, b = self._weights(layer_idx, layer_name)\n",
    "            W = tf.constant(W, name = 'weights')\n",
    "            b = tf.constant(b, name = 'bias')\n",
    "            conv2d = tf.nn.conv2d(prev_layer, filter = W, strides = [1,1,1,1], padding = 'SAME')\n",
    "            out = tf.nn.relu(conv2d + b)\n",
    "        setattr(self, layer_name, out)\n",
    "        \n",
    "    def avgpool(self, prev_layer, layer_name):\n",
    "        with tf.variable_scope(layer_name):\n",
    "            out = tf.nn.avg_pool(prev_layer,\n",
    "                                ksize = [1,2,2,1],\n",
    "                                strides = [1,2,2,1],\n",
    "                                padding = 'SAME')\n",
    "        setattr(self, layer_name, out)\n",
    "    \n",
    "    def load(self):\n",
    "        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n",
    "        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n",
    "        self.avgpool(self.conv1_2, 'avgpool1')\n",
    "        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n",
    "        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n",
    "        self.avgpool(self.conv2_2, 'avgpool2')\n",
    "        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n",
    "        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n",
    "        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n",
    "        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n",
    "        self.avgpool(self.conv3_4, 'avgpool3')\n",
    "        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n",
    "        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n",
    "        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n",
    "        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n",
    "        self.avgpool(self.conv4_4, 'avgpool4')\n",
    "        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n",
    "        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n",
    "        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n",
    "        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n",
    "        self.avgpool(self.conv5_4, 'avgpool5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##测试用\n",
    "vgg = VGG(tf.get_variable('img_in',shape=([1,333,250,3]),dtype = tf.float32, initializer = tf.zeros_initializer()))\n",
    "vgg.conv2d_relu(vgg.input_img, 0, 'conv1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def setup():\n",
    "    safe_mkdir('checkpoints')\n",
    "    safe_mkdir('outputs')\n",
    "\n",
    "class StyleTransfer(object):\n",
    "    def __init__(self, content_img, style_img, img_width, img_height):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.content_img = get_resized_img(content_img, img_width, img_height)\n",
    "        self.style_img = get_resized_img(style_img, img_width, img_height)\n",
    "        self.initial_img = generate_noise_image(self.content_img, img_width, img_height)\n",
    "        #定义全局超参,以及模型执行过程中用到的参数\n",
    "        #采集content error\n",
    "        self.content_layer = 'conv4_2'\n",
    "        #采集style error\n",
    "        self.style_layers = ['conv1_1','conv2_1','conv3_1','conv4_1','conv5_1']\n",
    "        self.content_w = 0.01\n",
    "        self.style_w = 1\n",
    "        self.style_layer_w = [0.5,1.0,1.5,3.0,4.0]\n",
    "        #记录当前进度\n",
    "        self.gstep = tf.Variable(0,dtype = tf.int32,\n",
    "                                trainable = False, name = 'global_step')\n",
    "        self.lr = 2.0\n",
    "    \n",
    "    def create_input(self):\n",
    "        #原文说要将style img,content img,generate img三图放在一个变量里一起训练\n",
    "        with tf.variable_scope('input') as scope:\n",
    "            self.input_img = tf.get_variable('in_img',shape = ([1,self.img_height,self.img_width,3]),\n",
    "                                            dtype = tf.float32,\n",
    "                                            initializer = tf.zeros_initializer())\n",
    "    \n",
    "    def load_vgg(self):\n",
    "        #加载vgg19模型,输入input_img得到计算结果,对content和style图片做平均中心化\n",
    "        self.vgg = VGG(self.input_img)\n",
    "        self.vgg.load()\n",
    "        self.content_img -= self.vgg.mean_pixels\n",
    "        self.style_img -= self.vgg.mean_pixels\n",
    "        \n",
    "    def _content_loss(self, P, F):\n",
    "        #如何计算contetn_loss\n",
    "        #P: content representation of the content image\n",
    "        #F: content representation of the generated image\n",
    "        #为什么要4*P.size\n",
    "        \"\"\"However, in practice, we’ve found that this function\n",
    "        makes it really slow to converge, so  people often replace the coefficient ½ \n",
    "        with 1/(4s) in which s is the product of the dimension  of P. \n",
    "        If P has dimension [5, 5, 3] then s = 5 * 5 * 3 = 75.  \"\"\"\n",
    "        self.content_loss = tf.reduce_sum((F-P)**2)/(4.0*P.size))\n",
    "        \n",
    "    def _gram_matrix(self, F, N, M):\n",
    "        #F的内积矩阵,同一层的不同激活图之间的协方差矩阵定义了风格\n",
    "        F = tf.reshape(F,(M,N))\n",
    "        return tf.matmul(tf.transpose(F),F)\n",
    "    \n",
    "    def _single_style_loss(self, a, g):\n",
    "        #计算style loss， a是style image的vgg计算结果,g是生成图的vgg计算结果\n",
    "        #N = depth, M = width*height\n",
    "        N = a.shape[3]\n",
    "        M = a.shape[1]*a.shape[2]\n",
    "        #计算A的style\n",
    "        A = self._gram_matrix(a, N, M)\n",
    "        G = self._gram_matrix(g, N, M)\n",
    "        #计算损失 alpha = beta = 0.5 为C,S的权重\n",
    "        return tf.reduce_mean((G-A)**2)/((2*N*M)**2)\n",
    "    \n",
    "    def _style_loss(self,A):\n",
    "        #计算每一层的loss，存起来\n",
    "        n_layers = len(A)\n",
    "        E = [self._single_style_loss(A[i],getattr(self.vgg,\n",
    "                                                 self.style_layers[i])) for i in range(n_layers)]\n",
    "        self.style_loss = sum([self.style_layer_w[i] * E[i] for i in range(n_layers)])\n",
    "        \n",
    "    def losses(self):\n",
    "        #总计的c_loss + s_loss\n",
    "        with tf.variable_scope('losses') as scope:\n",
    "            #打开一个session,计算传入content图的结果\n",
    "            with tf.Session() as sess:\n",
    "                #在原始图中添加并执行一个assign操作节点\n",
    "                sess.run(self.input_img.assign(self.content_img))\n",
    "                #定义content提取图操作\n",
    "                gen_img_content = getattr(self.vgg, self.content_layer)\n",
    "                #获取vgg对于生成图计算结果中第content_layer层的计算结果\n",
    "                #改变了input_img后，根据content_layer的计算图的定义，执行，生成内容图的content\n",
    "                content_img_content = sess.run(gen_img_content)\n",
    "            #定义C_loss的计算节点\n",
    "            self._content_loss(content_img_content,gen_img_content)\n",
    "            \n",
    "            #打开一个session,计算传入style图的结果\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(self.input_img.assign(self.style_img))\n",
    "                #改变input,获取定义的图，执行，获得结果\n",
    "                style_layers = sess.run([getattr(self.vgg,layer) for layer in self.style_layers])\n",
    "            #定义S_loss的计算节点\n",
    "            self._style_loss(style_layers)\n",
    "            #定义total_loss\n",
    "            self.total_loss = self.content_w * self.content_loss + self.style_w * self.style_loss\n",
    "    \n",
    "    #定义反向传播更新的梯度方向\n",
    "    def optimize(self):\n",
    "        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.total_loss,global_step = self.gstep)\n",
    "        \n",
    "    def create_summary(self):\n",
    "        #分门别类的整理loss\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('content loss', self.content_loss)\n",
    "            tf.summary.scalar('style loss', self.style_loss)\n",
    "            tf.summary.scalar('total loss', self.total_loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "            \n",
    "    def build(self):\n",
    "        self.create_input()\n",
    "        self.load_vgg()\n",
    "        self.losses()\n",
    "        self.optimize()\n",
    "        self.create_summary()\n",
    "        \n",
    "    def train(self, n_iters):\n",
    "        skip_step = 1\n",
    "        #打开一个session 传入噪声初始图片开始更新\n",
    "        with tf.Session() as sess:\n",
    "            #初始化模型变量\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            writer = tf.summary.FileWriter('graphs/style_transfer', sess.graph)\n",
    "            sess.run(self.input_img.assign(self.initial_img))\n",
    "            \n",
    "            saver = tf.train.Saver()\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/style_transfer/checkpoint'))\n",
    "            #当有检查点文件时，从文件恢复上次会话\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            initial_step = self.gstep.eval()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for index in range(initial_step, n_iters):\n",
    "                if index >= 5 and index <20:\n",
    "                    skip_step = 10\n",
    "                elif index >= 20:\n",
    "                    skip_step = 20\n",
    "                sess.run(self.opt)\n",
    "                if (index + 1) % skip_step == 0:\n",
    "                    gen_image, total_loss, summary = sess.run([self.input_img,\n",
    "                                                              self.total_loss,\n",
    "                                                              self.summary_op])\n",
    "                    gen_image = gen_image + self.vgg.mean_pixels\n",
    "                    writer.add_summary(summary, global_step=index)\n",
    "                    print('Step {}\\n Sum: {:5.1f}'.format(index+1,np.sum(gen_image)))\n",
    "                    print('    Loss: {:5.1f}'.format(total_loss))\n",
    "                    print('    Took: {} seconds'.format(time.time() - start_time))\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    filename = 'outputs/%d.png' % (index)\n",
    "                    save_image(filename, gen_image)\n",
    "\n",
    "                    if (index + 1) % 20 == 0 :\n",
    "                        saver.save(sess,'checkpoints/style_transfer/style_transfer',index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = StyleTransfer('content/deadpool.jpg', 'styles/guernica.jpg', 333, 250)\n",
    "machine.build()\n",
    "machine.train(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
