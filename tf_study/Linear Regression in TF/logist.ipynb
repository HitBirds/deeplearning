{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.12\n",
    "batch_size = 128\n",
    "n_epochs = 50\n",
    "n_train = 60000\n",
    "n_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#MNIST = input_data.read_data_sets('data/mnist',one_hot=True)\n",
    "#print(MNIST.train,MNIST.validation,MNIST.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import struct\n",
    "with open(os.path.join('data/mnist2','train-labels-idx1-ubyte'),'rb') as file:\n",
    "    print(struct.unpack(\">I\",file.read(4)))\n",
    "    print(file.read(8))\n",
    "    print(type(b'\\x00\\x00\\x08\\x01'))\n",
    "    print(struct.unpack(\">II\",b'\\x00\\x00\\x08\\x01\\x00\\x00\\xea`'))\n",
    "    print(file.read(8))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you have poor network,then you may need to download the mnist datasets,and extract them manually by using the gzip.open(in_file,'rb') as in,open(out_file,'wb') as out and shutil.copyfileobj(in,out) which is specified in utils.download_one_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/notmnist\\train-images-idx3-ubyte.gz already exists\n",
      "data/notmnist\\train-labels-idx1-ubyte.gz already exists\n",
      "data/notmnist\\t10k-images-idx3-ubyte.gz already exists\n",
      "data/notmnist\\t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Read in data\n",
    "#mnist_folder = 'data/mnist2'\n",
    "mnist_folder = 'data/notmnist'\n",
    "utils.download_mnist(mnist_folder)\n",
    "train,val,test = utils.read_mnist(mnist_folder,flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Create datasets and iterator\n",
    "#create training Dataset and batch it\n",
    "train_data= tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000)\n",
    "train_data = train_data.batch(batch_size)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "#create one iterator and initialize it with different datasets\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    train_data.output_types,\n",
    "    train_data.output_shapes)\n",
    "img, label = iterator.get_next()\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init = iterator.make_initializer(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 10\n"
     ]
    }
   ],
   "source": [
    "print(img.shape[1],label.shape[1])\n",
    "w_shape=img.shape[1].value\n",
    "b_shape = label.shape[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3:create weights and bias\n",
    "w1, b1 = tf.get_variable(name='weights1',dtype=tf.float32,initializer = tf.random_normal([w_shape,196])),tf.get_variable(name='bias1',dtype=tf.float32,initializer=tf.random_normal([196]))\n",
    "w2, b2 = tf.get_variable(name='weights2',dtype=tf.float32,initializer = tf.random_normal([196,64])),tf.get_variable(name='bias2',dtype=tf.float32,initializer=tf.random_normal([64]))\n",
    "w3, b3 = tf.get_variable(name='weights3',dtype=tf.float32,initializer = tf.random_normal([64,b_shape])),tf.get_variable(name='bias3',dtype=tf.float32,initializer=tf.random_normal([b_shape]))\n",
    "#step 4:build model\n",
    "#the model that returns logits,this logits will be later passed through softmax layer\n",
    "layer1 = tf.matmul(img,w1)+b1\n",
    "out1 = tf.nn.softmax(layer1)\n",
    "norm1 = tf.nn.batch_normalization(out1,0,1,None,None,0.001)\n",
    "layer2 = tf.matmul(norm1,w2)+b2\n",
    "out2 = tf.nn.softmax(layer2)\n",
    "norm2 = tf.nn.batch_normalization(out2,0,1,None,None,0.001)\n",
    "logits = tf.matmul(norm2,w3)+b3\n",
    "#logits = tf.matmul(layer2,w3)+b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5:define loss function\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=label,logits=logits)\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 6:define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7:calculate accuracy with test set\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds,1),tf.argmax(label,1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0:1.4912409032500067\n",
      "Total time: 6.933532476425171 seconds\n",
      "Average loss epoch 1:1.0547674894332886\n",
      "Total time: 9.76781177520752 seconds\n",
      "Average loss epoch 2:0.9893054723739624\n",
      "Total time: 12.90245246887207 seconds\n",
      "Average loss epoch 3:0.9509645955507146\n",
      "Total time: 15.531826257705688 seconds\n",
      "Average loss epoch 4:0.8869073603042337\n",
      "Total time: 18.298013925552368 seconds\n",
      "Average loss epoch 5:0.8152303981226544\n",
      "Total time: 21.436826467514038 seconds\n",
      "Average loss epoch 6:0.7863178285055382\n",
      "Total time: 24.14909601211548 seconds\n",
      "Average loss epoch 7:0.7636450717615527\n",
      "Total time: 26.96174144744873 seconds\n",
      "Average loss epoch 8:0.7302606262439906\n",
      "Total time: 29.86602544784546 seconds\n",
      "Average loss epoch 9:0.6730496232592782\n",
      "Total time: 32.76762533187866 seconds\n",
      "Average loss epoch 10:0.6525584255540093\n",
      "Total time: 35.584447383880615 seconds\n",
      "Average loss epoch 11:0.6449329026216685\n",
      "Total time: 38.160019874572754 seconds\n",
      "Average loss epoch 12:0.6330169646545898\n",
      "Total time: 40.68998742103577 seconds\n",
      "Average loss epoch 13:0.6218383106381394\n",
      "Total time: 43.22975420951843 seconds\n",
      "Average loss epoch 14:0.6216735365085824\n",
      "Total time: 46.139917612075806 seconds\n",
      "Average loss epoch 15:0.6152036196963732\n",
      "Total time: 48.929940938949585 seconds\n",
      "Average loss epoch 16:0.6056734466968581\n",
      "Total time: 51.828290700912476 seconds\n",
      "Average loss epoch 17:0.5925804935915525\n",
      "Total time: 54.686893701553345 seconds\n",
      "Average loss epoch 18:0.6038171988587047\n",
      "Total time: 58.0799195766449 seconds\n",
      "Average loss epoch 19:0.5966986022023267\n",
      "Total time: 62.4695770740509 seconds\n",
      "Average loss epoch 20:0.5915970270716867\n",
      "Total time: 65.07478880882263 seconds\n",
      "Average loss epoch 21:0.5845338168532349\n",
      "Total time: 67.63457822799683 seconds\n",
      "Average loss epoch 22:0.5754691295152486\n",
      "Total time: 70.52978706359863 seconds\n",
      "Average loss epoch 23:0.5724099412907001\n",
      "Total time: 73.34989476203918 seconds\n",
      "Average loss epoch 24:0.5740544423807499\n",
      "Total time: 76.07004880905151 seconds\n",
      "Average loss epoch 25:0.5680351313463478\n",
      "Total time: 78.75823545455933 seconds\n",
      "Average loss epoch 26:0.5660097648238027\n",
      "Total time: 81.76874303817749 seconds\n",
      "Average loss epoch 27:0.5561404150585796\n",
      "Total time: 84.88977670669556 seconds\n",
      "Average loss epoch 28:0.5541067370841669\n",
      "Total time: 87.98973369598389 seconds\n",
      "Average loss epoch 29:0.5536549638177073\n",
      "Total time: 90.94766068458557 seconds\n",
      "Average loss epoch 30:0.5510970697153447\n",
      "Total time: 93.88999319076538 seconds\n",
      "Average loss epoch 31:0.5458210496015327\n",
      "Total time: 96.86015963554382 seconds\n",
      "Average loss epoch 32:0.5503988436488219\n",
      "Total time: 99.7758481502533 seconds\n",
      "Average loss epoch 33:0.5355046650004941\n",
      "Total time: 102.78447556495667 seconds\n",
      "Average loss epoch 34:0.5343664157182672\n",
      "Total time: 105.4647889137268 seconds\n",
      "Average loss epoch 35:0.5447621789089468\n",
      "Total time: 108.13960361480713 seconds\n",
      "Average loss epoch 36:0.5349962124297786\n",
      "Total time: 110.80216836929321 seconds\n",
      "Average loss epoch 37:0.5347194657422776\n",
      "Total time: 113.81378555297852 seconds\n",
      "Average loss epoch 38:0.5270741038544233\n",
      "Total time: 116.61978530883789 seconds\n",
      "Average loss epoch 39:0.5260885511026826\n",
      "Total time: 119.34526228904724 seconds\n",
      "Average loss epoch 40:0.5284536429615908\n",
      "Total time: 121.92993450164795 seconds\n",
      "Average loss epoch 41:0.5280538423809894\n",
      "Total time: 124.75976610183716 seconds\n",
      "Average loss epoch 42:0.5235339304388955\n",
      "Total time: 128.00957870483398 seconds\n",
      "Average loss epoch 43:0.5190510795559994\n",
      "Total time: 131.3116660118103 seconds\n",
      "Average loss epoch 44:0.51649344965469\n",
      "Total time: 134.30932426452637 seconds\n",
      "Average loss epoch 45:0.5115548433259476\n",
      "Total time: 137.41043758392334 seconds\n",
      "Average loss epoch 46:0.5095600344413935\n",
      "Total time: 140.5420639514923 seconds\n",
      "Average loss epoch 47:0.5094082782434862\n",
      "Total time: 143.69838309288025 seconds\n",
      "Average loss epoch 48:0.5092299057993778\n",
      "Total time: 146.70510482788086 seconds\n",
      "Average loss epoch 49:0.505797507180724\n",
      "Total time: 149.65835666656494 seconds\n",
      "Accuracy 0.9003\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter('./graphs/logreg',tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #train the model n_epochs times\n",
    "    for i in range(n_epochs):\n",
    "        sess.run(train_init)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer,loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print('Average loss epoch {0}:{1}'.format(i,total_loss/n_batches))\n",
    "        print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "        \n",
    "    #test model\n",
    "    sess.run(test_init)\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))\n",
    "writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
